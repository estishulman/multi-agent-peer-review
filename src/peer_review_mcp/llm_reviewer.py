# # llm_reviewer.py
# import os
# from openai import OpenAI
#
# client = OpenAI()
#
# def review_with_llm(question: str) -> dict:
#     response = client.chat.completions.create(
#         model="gpt-4.1-mini",
#         messages=[
#             {
#                 "role": "system",
#                 "content": (
#                     "You are a strict peer reviewer. "
#                     "Return only risks, assumptions, and missing edge cases. "
#                     "Do NOT provide a full answer."
#                 )
#             },
#             {
#                 "role": "user",
#                 "content": question
#             }
#         ],
#         temperature=0.2
#     )
#
#     return {
#         "severity": "medium",
#         "insights": [
#             response.choices[0].message.content
#         ],
#         "must_fix": [],
#         "notes": ["Generated by LLM reviewer"]
#     }
